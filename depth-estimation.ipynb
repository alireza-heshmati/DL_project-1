{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-27T12:25:46.855857Z","iopub.execute_input":"2022-01-27T12:25:46.856227Z","iopub.status.idle":"2022-01-27T12:25:46.878435Z","shell.execute_reply.started":"2022-01-27T12:25:46.856157Z","shell.execute_reply":"2022-01-27T12:25:46.877822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport timeit\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:33:49.024678Z","iopub.execute_input":"2022-01-27T12:33:49.024945Z","iopub.status.idle":"2022-01-27T12:33:49.02831Z","shell.execute_reply.started":"2022-01-27T12:33:49.024919Z","shell.execute_reply":"2022-01-27T12:33:49.027695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color = np.array(Image.open('../input/nyu-depth-v2/nyu_data/data/nyu2_test/00000_colors.png'))\ndepth = np.array(Image.open('../input/nyu-depth-v2/nyu_data/data/nyu2_test/00000_depth.png'))\ncolor.shape,depth.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:40:43.685127Z","iopub.execute_input":"2022-01-27T12:40:43.685905Z","iopub.status.idle":"2022-01-27T12:40:43.72414Z","shell.execute_reply.started":"2022-01-27T12:40:43.685873Z","shell.execute_reply":"2022-01-27T12:40:43.723593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.imshow(color)\nplt.figure()\nplt.imshow(depth)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:40:44.135984Z","iopub.execute_input":"2022-01-27T12:40:44.136525Z","iopub.status.idle":"2022-01-27T12:40:44.537454Z","shell.execute_reply.started":"2022-01-27T12:40:44.136489Z","shell.execute_reply":"2022-01-27T12:40:44.536692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min(depth.flatten()),max(depth.flatten())","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:40:56.99136Z","iopub.execute_input":"2022-01-27T12:40:56.992186Z","iopub.status.idle":"2022-01-27T12:40:57.027023Z","shell.execute_reply.started":"2022-01-27T12:40:56.99215Z","shell.execute_reply":"2022-01-27T12:40:57.026171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"depth","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:49:39.069641Z","iopub.execute_input":"2022-01-27T12:49:39.069878Z","iopub.status.idle":"2022-01-27T12:49:39.075183Z","shell.execute_reply.started":"2022-01-27T12:49:39.069851Z","shell.execute_reply":"2022-01-27T12:49:39.074733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision.models\nimport collections\nimport math\nimport torch.nn.functional as F\nimport imagenet.mobilenet\nimport time\nimport torch.nn.parallel\n\n\ndef weights_init(m):\n    # Initialize kernel weights with Gaussian distributions\n    if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif isinstance(m, nn.ConvTranspose2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n        \ndef conv(in_channels, out_channels, kernel_size):\n    padding = (kernel_size-1) // 2\n    assert 2*padding == kernel_size-1, \"parameters incorrect. kernel={}, padding={}\".format(kernel_size, padding)\n    return nn.Sequential(\n          nn.Conv2d(in_channels,out_channels,kernel_size,stride=1,padding=padding,bias=False),\n          nn.BatchNorm2d(out_channels),\n          nn.ReLU(inplace=True),\n        )\n\ndef depthwise(in_channels, kernel_size):\n    padding = (kernel_size-1) // 2\n    assert 2*padding == kernel_size-1, \"parameters incorrect. kernel={}, padding={}\".format(kernel_size, padding)\n    return nn.Sequential(\n          nn.Conv2d(in_channels,in_channels,kernel_size,stride=1,padding=padding,bias=False,groups=in_channels),\n          nn.BatchNorm2d(in_channels),\n          nn.ReLU(inplace=True),\n        )\n\ndef pointwise(in_channels, out_channels):\n    return nn.Sequential(\n          nn.Conv2d(in_channels,out_channels,1,1,0,bias=False),\n          nn.BatchNorm2d(out_channels),\n          nn.ReLU(inplace=True),\n        )\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MobileNet(nn.Module):\n    def __init__(self, relu6=True):\n        super(MobileNet, self).__init__()\n\n        def relu(relu6):\n            if relu6:\n                return nn.ReLU6(inplace=True)\n            else:\n                return nn.ReLU(inplace=True)\n\n        def conv_bn(inp, oup, stride, relu6):\n            return nn.Sequential(\n                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n                nn.BatchNorm2d(oup),\n                relu(relu6),\n            )\n\n        def conv_dw(inp, oup, stride, relu6):\n            return nn.Sequential(\n                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n                nn.BatchNorm2d(inp),\n                relu(relu6),\n    \n                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n                relu(relu6),\n            )\n\n        self.model = nn.Sequential(\n            conv_bn(  3,  32, 2, relu6), \n            conv_dw( 32,  64, 1, relu6),\n            conv_dw( 64, 128, 2, relu6),\n            conv_dw(128, 128, 1, relu6),\n            conv_dw(128, 256, 2, relu6),\n            conv_dw(256, 256, 1, relu6),\n            conv_dw(256, 512, 2, relu6),\n            conv_dw(512, 512, 1, relu6),\n            conv_dw(512, 512, 1, relu6),\n            conv_dw(512, 512, 1, relu6),\n            conv_dw(512, 512, 1, relu6),\n            conv_dw(512, 512, 1, relu6),\n            conv_dw(512, 1024, 2, relu6),\n            conv_dw(1024, 1024, 1, relu6),\n            nn.AvgPool2d(7),\n        )\n        self.fc = nn.Linear(1024, 1000)\n\n    def forward(self, x):\n        x = self.model(x)\n        x = x.view(-1, 1024)\n        x = self.fc(x)\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MobileNetSkipAdd(nn.Module):\n    def __init__(self, output_size, pretrained=True):\n\n        super(MobileNetSkipAdd, self).__init__()\n        self.output_size = output_size\n        mobilenet = imagenet.mobilenet.MobileNet()\n        if pretrained:\n            pretrained_path = os.path.join('imagenet', 'results', 'imagenet.arch=mobilenet.lr=0.1.bs=256', 'model_best.pth.tar')\n            checkpoint = torch.load(pretrained_path)\n            state_dict = checkpoint['state_dict']\n\n            from collections import OrderedDict\n            new_state_dict = OrderedDict()\n            for k, v in state_dict.items():\n                name = k[7:] # remove `module.`\n                new_state_dict[name] = v\n            mobilenet.load_state_dict(new_state_dict)\n        else:\n            mobilenet.apply(weights_init)\n\n        for i in range(14):\n            setattr( self, 'conv{}'.format(i), mobilenet.model[i])\n\n        # NNconv5\n        kernel_size = 5\n        self.decode_conv1 = nn.Sequential(\n            depthwise(1024, kernel_size),\n            pointwise(1024, 512))\n        self.decode_conv2 = nn.Sequential(\n            depthwise(512, kernel_size),\n            pointwise(512, 256))\n        self.decode_conv3 = nn.Sequential(\n            depthwise(256, kernel_size),\n            pointwise(256, 128))\n        self.decode_conv4 = nn.Sequential(\n            depthwise(128, kernel_size),\n            pointwise(128, 64))\n        self.decode_conv5 = nn.Sequential(\n            depthwise(64, kernel_size),\n            pointwise(64, 32))\n        self.decode_conv6 = pointwise(32, 1)\n        weights_init(self.decode_conv1)\n        weights_init(self.decode_conv2)\n        weights_init(self.decode_conv3)\n        weights_init(self.decode_conv4)\n        weights_init(self.decode_conv5)\n        weights_init(self.decode_conv6)\n\n    def forward(self, x):\n        # skip connections: dec4: enc1\n        # dec 3: enc2 or enc3\n        # dec 2: enc4 or enc5\n        for i in range(14):\n            layer = getattr(self, 'conv{}'.format(i))\n            x = layer(x)\n            # print(\"{}: {}\".format(i, x.size()))\n            if i==1:\n                x1 = x\n            elif i==3:\n                x2 = x\n            elif i==5:\n                x3 = x\n        for i in range(1,6):\n            layer = getattr(self, 'decode_conv{}'.format(i))\n            x = layer(x)\n            x = F.interpolate(x, scale_factor=2, mode='nearest')\n            if i==4:\n                x = x + x1\n            elif i==3:\n                x = x + x2\n            elif i==2:\n                x = x + x3\n            # print(\"{}: {}\".format(i, x.size()))\n        x = self.decode_conv6(x)\n        return x\n    \nmodel_bcresnet = BcResNetModel()\nprint(model_bcresnet)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}